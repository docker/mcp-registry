name: kgrag-mcp-server
image: mcp/kgrag_mcp_server
type: server
meta:
  category: productivity
  tags:
    - knowledge-graph
    - search
    - productivity
about:
  title: Knowledge Graph
  description: |-
    Manage, ingest, and query structured/unstructured data.
    Designed to integrate with Neo4j, AWS S3, Redis, Qdrant, and LLMs.
  icon: https://avatars.githubusercontent.com/u/6775950?v=4

source:
  project: https://github.com/gzileni/kgrag_mcp_server
  branch: main
  commit: 79ae98a75fb5248a6b574b00d3020b3412e53667

config:
  description: Configure the connection to the Knowledge Graph MCP Server
  env:
    - name: LLM_MODEL_TYPE
      example: ollama
      value: '{{kgrag-mcp-server.llm_model_type}}'
    - name: LLM_MODEL_NAME
      example: llama3.2
      value: '{{kgrag-mcp-server.llm_model_name}}'
    - name: API_KEY
      example: sk-...
      value: '{{kgrag-mcp-server.api_key}}'
    - name: LLM_URL
      example: http://localhost:11434
      value: '{{kgrag-mcp-server.llm_url}}'
    - name: TEMPERATURE
      example: "0.5"
      value: '{{kgrag-mcp-server.temperature}}'

    # Vectors & Collections
    - name: VECTORDB_SENTENCE_MODEL
      example: BAAI/bge-small-en-v1.5
      value: '{{kgrag-mcp-server.vectordb_sentence_model}}'
    - name: COLLECTION_NAME
      example: kgrag_data
      value: '{{kgrag-mcp-server.collection_name}}'

    # Model embedding
    - name: MODEL_EMBEDDING
      example: nomic-embed-text
      value: '{{kgrag-mcp-server.model_embedding}}'
    - name: LLM_EMBEDDING_URL
      example: http://localhost:11434
      value: '{{kgrag-mcp-server.llm_embedding_url}}'

    # AWS
    - name: AWS_ACCESS_KEY_ID
      example: AK...
      value: '{{kgrag-mcp-server.aws_access_key_id}}'
    - name: AWS_SECRET_ACCESS_KEY
      example: cG....
      value: '{{kgrag-mcp-server.aws_secret_access_key}}'
    - name: AWS_REGION
      example: eu-central-1
      value: '{{kgrag-mcp-server.aws_region}}'
    - name: AWS_BUCKET_NAME
      example: my_bucket
      value: '{{kgrag-mcp-server.aws_bucket_name}}'

  parameters:
  type: object
  properties:
    llm_model_type:
      type: string
      default: ollama
      description: LLM provider (e.g., ollama, openai)
    llm_model_name:
      type: string
      default: llama3.2
      description: Name of the LLM model to use
    api_key:
      type: string
      description: API key for the LLM provider (not required for local Ollama)
    llm_url:
      type: string
      default: http://localhost:11434
      description: Base URL of the LLM provider or gateway (e.g., Ollama/OpenAI proxy)
    temperature:
      type: number
      default: 0.5
      description: Sampling temperature (range 0â€“2)

    # Vectors & Collections
    vectordb_sentence_model:
      type: string
      default: BAAI/bge-small-en-v1.5
      description: Sentence embedding model for the vector database
    collection_name:
      type: string
      default: kgrag_data
      description: Name of the collection/index in the vector database

    # Model embedding
    model_embedding:
      type: string
      default: nomic-embed-text
      description: Model used for generating embeddings
    llm_embedding_url:
      type: string
      default: http://localhost:11434
      description: Endpoint for generating embeddings

    # AWS (optional)
    aws_access_key_id:
      type: string
      description: AWS Access Key ID
    aws_secret_access_key:
      type: string
      description: AWS Secret Access Key
    aws_region:
      type: string
      default: eu-central-1
      description: AWS region
    aws_bucket_name:
      type: string
      description: AWS S3 bucket name
  required:
    - llm_model_type
    - llm_model_name

